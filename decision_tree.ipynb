{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "534f2e28",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.model_selection import StratifiedShuffleSplit, GridSearchCV, ShuffleSplit\n",
    "from sklearn.metrics import make_scorer, r2_score\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "31643cbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3296, 2) (3296, 2, 498) (3296,)\n"
     ]
    }
   ],
   "source": [
    "data = np.load(\"climbing_dataset.npz\", allow_pickle=True)\n",
    "holds = data[\"X\"]\n",
    "y = data[\"y\"]\n",
    "names = data[\"names\"]\n",
    "global_features = data[\"global_features\"]\n",
    "print(global_features.shape, holds.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "de717823",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3296, 998) (3296,)\n"
     ]
    }
   ],
   "source": [
    "X_holds = holds.reshape(holds.shape[0], -1)\n",
    "X = np.concatenate([X_holds, global_features], axis=1)\n",
    "\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d56a912",
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = np.arange(10, 31, 1)\n",
    "y_binned = np.digitize(y, bins, right=False)\n",
    "X_train, X_test = None, None\n",
    "y_train, y_test = None, None\n",
    "split = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
    "for train_idx, test_idx in split.split(X, y_binned):\n",
    "    X_train, X_test = X[train_idx], X[test_idx]\n",
    "    y_train, y_test = y[train_idx], y[test_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3479153",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb \n",
    "model = xgb.XGBRegressor(   objective='reg:squarederror',   \n",
    "                            learning_rate=0.005, \n",
    "                            max_depth=0, \n",
    "                            random_state=42,\n",
    "                            eval_metric = 'rmse',\n",
    "                            subsample = 0.1,\n",
    "                            colsample_bytree =  0.1, \n",
    "                            n_estimators=20000,\n",
    "                            gamma = 10)\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = model.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04ed0376",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "\n",
    "#regressor = RandomForestRegressor(n_estimators=1000, random_state=0, oob_score=True)\n",
    "\n",
    "\n",
    "regressor.fit(X_train, y_train)\n",
    "y_pred = regressor.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "c92ea87b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 432 candidates, totalling 2160 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\shado\\Documents\\Development\\TB2 Project\\TB2-Classifier\\.venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:516: FitFailedWarning: \n",
      "540 fits failed out of a total of 2160.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "540 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\shado\\Documents\\Development\\TB2 Project\\TB2-Classifier\\.venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\shado\\Documents\\Development\\TB2 Project\\TB2-Classifier\\.venv\\Lib\\site-packages\\xgboost\\core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\shado\\Documents\\Development\\TB2 Project\\TB2-Classifier\\.venv\\Lib\\site-packages\\xgboost\\sklearn.py\", line 1365, in fit\n",
      "    self._Booster = train(\n",
      "                    ^^^^^^\n",
      "  File \"c:\\Users\\shado\\Documents\\Development\\TB2 Project\\TB2-Classifier\\.venv\\Lib\\site-packages\\xgboost\\core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\shado\\Documents\\Development\\TB2 Project\\TB2-Classifier\\.venv\\Lib\\site-packages\\xgboost\\training.py\", line 199, in train\n",
      "    bst.update(dtrain, iteration=i, fobj=obj)\n",
      "  File \"c:\\Users\\shado\\Documents\\Development\\TB2 Project\\TB2-Classifier\\.venv\\Lib\\site-packages\\xgboost\\core.py\", line 2433, in update\n",
      "    _check_call(\n",
      "  File \"c:\\Users\\shado\\Documents\\Development\\TB2 Project\\TB2-Classifier\\.venv\\Lib\\site-packages\\xgboost\\core.py\", line 323, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value -1 for Parameter max_depth should be greater equal to 0\n",
      "max_depth: Maximum depth of the tree; 0 indicates no limit; a limit is required for depthwise policy\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "c:\\Users\\shado\\Documents\\Development\\TB2 Project\\TB2-Classifier\\.venv\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1135: UserWarning: One or more of the test scores are non-finite: [        nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan  3.92044243  3.94519131  4.04475493\n",
      "  3.14815427  3.12450993  3.09802188  3.01976664  2.87833417  2.8138436\n",
      "  3.27866768  3.31097139  3.3684162   2.83646442  2.73511937  2.74389999\n",
      "  2.74985854  2.59493026  2.59157741  2.88331065  2.77998963  2.74081403\n",
      "  2.68171577  2.50098876  2.4077142   2.61823499  2.43579783  2.34357037\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan  5.23578044  5.27999803  5.33856994\n",
      "  3.56528611  3.66866107  3.71539779  3.0560707   3.03236041  3.07179233\n",
      "  4.17501576  4.2454823   4.25407854  3.03839722  3.07861338  3.09788443\n",
      "  2.77881669  2.69798037  2.69119036  3.27726123  3.28192593  3.28075123\n",
      "  2.60939338  2.5462861   2.55812394  2.48727566  2.37990215  2.38671174\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan 12.51874047 12.44464065 12.42540117\n",
      "  7.70013527  7.69178351  7.71740239  5.22766079  5.29441421  5.33724483\n",
      " 10.67622117 10.58277725 10.5301863   6.07183987  6.04417375  6.04990355\n",
      "  4.15464283  4.21286982  4.25542381  8.68303777  8.56112009  8.50274396\n",
      "  4.54821325  4.53011636  4.52957378  3.19576058  3.21643179  3.2583136\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan 15.98364431 15.90573376 15.87841357\n",
      " 11.28269927 11.20811682 11.18811561  7.723849    7.72625573  7.75258178\n",
      " 14.54943656 14.47103606 14.42244247  9.36388528  9.28461651  9.2455078\n",
      "  6.1021725   6.07459501  6.0846718  12.91321084 12.76523499 12.69026955\n",
      "  7.39221893  7.26729589  7.22338706  4.58312309  4.55393016  4.55461939\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan  3.8147533   3.85966137  3.97306496\n",
      "  3.08961397  2.98632563  3.03498047  2.94891365  2.7818595   2.77522474\n",
      "  3.24098076  3.22660726  3.32936158  2.81425153  2.69830959  2.66725104\n",
      "  2.75450474  2.59590593  2.55502981  2.78015436  2.71716901  2.73537149\n",
      "  2.60190984  2.46010899  2.46461226  2.54030866  2.40938593  2.40833897\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan  5.07643208  5.13879498  5.27715173\n",
      "  3.48394896  3.57355872  3.65725927  3.01567604  2.97832253  3.02724736\n",
      "  4.05686612  4.1402513   4.17638342  2.94417626  3.00423296  3.01670321\n",
      "  2.73260344  2.67283998  2.62493647  3.17179751  3.16683777  3.20622781\n",
      "  2.59110279  2.51265208  2.47611084  2.4976727   2.37520578  2.32442535\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan 11.87852741 11.9265303  11.95633597\n",
      "  7.40683138  7.52253426  7.5933286   5.06600256  5.18112673  5.25665385\n",
      "  9.85158912  9.85706305  9.85201696  5.74969929  5.83893516  5.891645\n",
      "  4.01166114  4.08688878  4.1614939   7.56658325  7.51387345  7.50684408\n",
      "  4.20043484  4.25180025  4.29895274  3.04892086  3.10974286  3.1832038\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan 15.3532129  15.34834121 15.33310627\n",
      " 10.72265914 10.80723757 10.85648717  7.40137786  7.52496035  7.61712039\n",
      " 13.67049571 13.60366552 13.57025429  8.658106    8.70199797  8.76061629\n",
      "  5.74859537  5.84111456  5.91769011 11.57730175 11.45327662 11.39517176\n",
      "  6.43881677  6.43861911  6.46046197  4.18656727  4.2445611   4.29920704\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan  3.7433567   3.89013308  3.94092425\n",
      "  3.03091606  3.03890834  3.02152922  2.92082824  2.83356767  2.77109831\n",
      "  3.19496674  3.25471148  3.25002288  2.81183539  2.73237174  2.7051741\n",
      "  2.70978586  2.59898152  2.5553513   2.80092463  2.70811578  2.69360464\n",
      "  2.61511974  2.46395839  2.42355993  2.56039467  2.39850782  2.39186636\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan  5.02711956  5.16774113  5.22008736\n",
      "  3.44805215  3.58130879  3.63393021  3.00813294  2.98118701  3.01831227\n",
      "  3.98127017  4.09091515  4.15348049  2.91639256  2.97682808  2.98583592\n",
      "  2.70216148  2.65789936  2.60961792  3.10321543  3.16125575  3.19129413\n",
      "  2.59467022  2.54855839  2.52312539  2.50642096  2.4033693   2.37604961\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan 11.71491709 11.8518893  11.92119321\n",
      "  7.27973272  7.45830135  7.53839591  4.98737087  5.1247289   5.21122046\n",
      "  9.55302257  9.67613733  9.74703038  5.6364304   5.76637898  5.85544279\n",
      "  3.94511494  4.05659665  4.14004184  7.21728848  7.24987069  7.27707711\n",
      "  4.11995056  4.21326032  4.27394899  3.02335012  3.09485607  3.16511964\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan 15.12180436 15.1757282  15.20727227\n",
      " 10.5568931  10.70690382 10.80099508  7.27539426  7.44363232  7.55168657\n",
      " 13.28103066 13.29288302 13.31850038  8.46230908  8.58234883  8.67622692\n",
      "  5.64509597  5.76566756  5.85829826 11.02742412 10.9552507  10.91437756\n",
      "  6.22610157  6.29710233  6.35335175  4.11571194  4.20286865  4.26959255]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: {'colsample_bytree': 0.2, 'learning_rate': 0.005, 'max_depth': 2, 'n_estimators': 200, 'subsample': 0.2}\n",
      "Best CV R²: 15.983644305398943\n",
      "Test R²: 0.26753922219937964\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    #'num_leaves': [31, 63, 127],\n",
    "    'learning_rate': [0.1, 0.05, 0.01, .005],\n",
    "    'n_estimators': [200, 500, 1000],\n",
    "    'max_depth': [-1, 2,3, 5],\n",
    "    'subsample': [0.2,0.4,0.6],\n",
    "    'colsample_bytree': [0.2,0.4,0.6,]\n",
    "}\n",
    "\n",
    "scorer = make_scorer(mean_squared_error)  # or use neg_mean_squared_error, etc.\n",
    "cv_splitter = ShuffleSplit(n_splits=5, test_size=0.2, random_state=42)\n",
    "# -----------------------------------\n",
    "# Grid search\n",
    "# -----------------------------------\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=model,\n",
    "    param_grid=param_grid,\n",
    "    scoring=scorer,\n",
    "    cv=cv_splitter,\n",
    "    verbose=2,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# -----------------------------------\n",
    "# Results\n",
    "# -----------------------------------\n",
    "print(\"Best params:\", grid_search.best_params_)\n",
    "print(\"Best CV R²:\", grid_search.best_score_)\n",
    "\n",
    "# Evaluate on test set\n",
    "best_model = grid_search.best_estimator_\n",
    "test_r2 = r2_score(y_test, best_model.predict(X_test))\n",
    "print(\"Test R²:\", test_r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "71391d10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_colsample_bytree</th>\n",
       "      <th>param_learning_rate</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>param_subsample</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>215</th>\n",
       "      <td>4.973810</td>\n",
       "      <td>0.102138</td>\n",
       "      <td>0.024201</td>\n",
       "      <td>0.008034</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.05</td>\n",
       "      <td>5</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.6</td>\n",
       "      <td>{'colsample_bytree': 0.4, 'learning_rate': 0.0...</td>\n",
       "      <td>2.071121</td>\n",
       "      <td>2.521604</td>\n",
       "      <td>2.294859</td>\n",
       "      <td>2.356078</td>\n",
       "      <td>2.378465</td>\n",
       "      <td>2.324425</td>\n",
       "      <td>0.146860</td>\n",
       "      <td>324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>4.945161</td>\n",
       "      <td>0.047972</td>\n",
       "      <td>0.035102</td>\n",
       "      <td>0.004054</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.10</td>\n",
       "      <td>5</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.6</td>\n",
       "      <td>{'colsample_bytree': 0.2, 'learning_rate': 0.1...</td>\n",
       "      <td>2.063094</td>\n",
       "      <td>2.570905</td>\n",
       "      <td>2.224817</td>\n",
       "      <td>2.380786</td>\n",
       "      <td>2.478250</td>\n",
       "      <td>2.343570</td>\n",
       "      <td>0.181093</td>\n",
       "      <td>323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214</th>\n",
       "      <td>5.006477</td>\n",
       "      <td>0.042703</td>\n",
       "      <td>0.018600</td>\n",
       "      <td>0.000800</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.05</td>\n",
       "      <td>5</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.4</td>\n",
       "      <td>{'colsample_bytree': 0.4, 'learning_rate': 0.0...</td>\n",
       "      <td>2.182863</td>\n",
       "      <td>2.561723</td>\n",
       "      <td>2.402975</td>\n",
       "      <td>2.301096</td>\n",
       "      <td>2.427372</td>\n",
       "      <td>2.375206</td>\n",
       "      <td>0.127098</td>\n",
       "      <td>322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>359</th>\n",
       "      <td>5.257670</td>\n",
       "      <td>0.132196</td>\n",
       "      <td>0.027400</td>\n",
       "      <td>0.008777</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.05</td>\n",
       "      <td>5</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.6</td>\n",
       "      <td>{'colsample_bytree': 0.6, 'learning_rate': 0.0...</td>\n",
       "      <td>2.150157</td>\n",
       "      <td>2.567801</td>\n",
       "      <td>2.317343</td>\n",
       "      <td>2.406710</td>\n",
       "      <td>2.438236</td>\n",
       "      <td>2.376050</td>\n",
       "      <td>0.138600</td>\n",
       "      <td>321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>4.832805</td>\n",
       "      <td>0.094095</td>\n",
       "      <td>0.027302</td>\n",
       "      <td>0.008329</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.05</td>\n",
       "      <td>5</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.4</td>\n",
       "      <td>{'colsample_bytree': 0.2, 'learning_rate': 0.0...</td>\n",
       "      <td>2.116235</td>\n",
       "      <td>2.552281</td>\n",
       "      <td>2.372718</td>\n",
       "      <td>2.430647</td>\n",
       "      <td>2.427630</td>\n",
       "      <td>2.379902</td>\n",
       "      <td>0.144319</td>\n",
       "      <td>320</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "215       4.973810      0.102138         0.024201        0.008034   \n",
       "35        4.945161      0.047972         0.035102        0.004054   \n",
       "214       5.006477      0.042703         0.018600        0.000800   \n",
       "359       5.257670      0.132196         0.027400        0.008777   \n",
       "70        4.832805      0.094095         0.027302        0.008329   \n",
       "\n",
       "     param_colsample_bytree  param_learning_rate  param_max_depth  \\\n",
       "215                     0.4                 0.05                5   \n",
       "35                      0.2                 0.10                5   \n",
       "214                     0.4                 0.05                5   \n",
       "359                     0.6                 0.05                5   \n",
       "70                      0.2                 0.05                5   \n",
       "\n",
       "     param_n_estimators  param_subsample  \\\n",
       "215                1000              0.6   \n",
       "35                 1000              0.6   \n",
       "214                1000              0.4   \n",
       "359                1000              0.6   \n",
       "70                 1000              0.4   \n",
       "\n",
       "                                                params  split0_test_score  \\\n",
       "215  {'colsample_bytree': 0.4, 'learning_rate': 0.0...           2.071121   \n",
       "35   {'colsample_bytree': 0.2, 'learning_rate': 0.1...           2.063094   \n",
       "214  {'colsample_bytree': 0.4, 'learning_rate': 0.0...           2.182863   \n",
       "359  {'colsample_bytree': 0.6, 'learning_rate': 0.0...           2.150157   \n",
       "70   {'colsample_bytree': 0.2, 'learning_rate': 0.0...           2.116235   \n",
       "\n",
       "     split1_test_score  split2_test_score  split3_test_score  \\\n",
       "215           2.521604           2.294859           2.356078   \n",
       "35            2.570905           2.224817           2.380786   \n",
       "214           2.561723           2.402975           2.301096   \n",
       "359           2.567801           2.317343           2.406710   \n",
       "70            2.552281           2.372718           2.430647   \n",
       "\n",
       "     split4_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "215           2.378465         2.324425        0.146860              324  \n",
       "35            2.478250         2.343570        0.181093              323  \n",
       "214           2.427372         2.375206        0.127098              322  \n",
       "359           2.438236         2.376050        0.138600              321  \n",
       "70            2.427630         2.379902        0.144319              320  "
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df = pd.DataFrame(grid_search.cv_results_)\n",
    "results_df = results_df.dropna()\n",
    "\n",
    "results_df_sorted = results_df.sort_values(by='mean_test_score', ascending=True)\n",
    "# Show all columns (optional)\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "# Display the first few rows\n",
    "results_df_sorted.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "dfe1c560",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train RMSE: 0.444\n",
      "RMSE: 1.270\n",
      "R²: 0.927\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "train_rsme = np.sqrt(mean_squared_error(y_train, model.predict(X_train)))\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f'Train RMSE: {train_rsme:.3f}')\n",
    "print(f'RMSE: {rmse:.3f}')\n",
    "print(f'R²: {r2:.3f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
